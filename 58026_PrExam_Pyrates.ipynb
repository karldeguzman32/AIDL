{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "58026_PrExam_Pyrates.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karldeguzman32/AIDL/blob/main/58026_PrExam_Pyrates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "CU_3p1s4xuKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1 Perceptron Algorithm for NOR\n",
        "The activation function and perceptron function was implemented to determine if the output of the inputs x1 and x2 is 0 or 1 since the weights and bias are given."
      ],
      "metadata": {
        "id": "J1Q7te4fvmaO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGGuTI96p2Bi"
      },
      "outputs": [],
      "source": [
        "def activation_function(y):\n",
        "    if y > 0:\n",
        "        y = 1\n",
        "    elif y <= 0:\n",
        "        y = 0\n",
        "    return y\n",
        "    \n",
        "def perceptron(x):\n",
        "    # y = w1x1 + w2x2 + b\n",
        "    y = np.dot(W, x) + b\n",
        "    # y = 1 if Wx+b > 0 else y = 0 \n",
        "    y = activation_function(y)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# W = weights of the perceptron model\n",
        "W = np.array([-1, -1])\n",
        "# b = bias of the model\n",
        "b = 1\n",
        "\n",
        "input1 = np.array([0, 0])\n",
        "input2 = np.array([0, 1])\n",
        "input3 = np.array([1, 0])\n",
        "input4 = np.array([1, 1])\n",
        "\n",
        "print(f\"NOR(0, 0) = {perceptron(input1)}\")\n",
        "print(f\"NOR(1, 0) = {perceptron(input2)}\")\n",
        "print(f\"NOR(0, 1) = {perceptron(input3)}\")\n",
        "print(f\"NOR(1, 1) = {perceptron(input4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WJ_Dk4EGRrN",
        "outputId": "dd4be437-d708-441b-fd1d-270a57dce128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOR(0, 0) = 1\n",
            "NOR(1, 0) = 0\n",
            "NOR(0, 1) = 0\n",
            "NOR(1, 1) = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 Features and Targets\n",
        "For the features and targets, is the initialization of the based on the given. There were three weights initialized. For the features it would be [1, 0] and 2.86 for the target. "
      ],
      "metadata": {
        "id": "_XmQrRGxxKCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Features\n",
        "X = [1, 0]\n",
        "#Target\n",
        "y_target = 2.86\n",
        "#Weights\n",
        "w1 = [[1,-1],[-1,1]]\n",
        "w2 = [[1,2], [2,1]]\n",
        "w3 = [-1,1]"
      ],
      "metadata": {
        "id": "H3ZcbyFtxL9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3 Forward Propagation\n",
        "For the forward propagation, on this number there are already given value of x and weights that can help to compute the hidden layer, three hidden layer are being \n",
        "executed which is composed of z(n) and activation function as well, for the hidden layer 1 the z1 is the dot product of x and the first weight and for its activation function\n",
        "tanh was being used, that is the same pattern for the hidden layer 2 and 3 where dot product was used and the activation function is tanh, for the output layer it is the final output of the propagation."
      ],
      "metadata": {
        "id": "CWkVC9eVyUhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fwd_prop(X, w1, w2, w3):\n",
        "  #hiddenlayer1\n",
        "  z1 = np.dot(X, w1)\n",
        "  a1 = np.tanh(z1)\n",
        "  #hiddenlayer2\n",
        "  z2 = np.dot(a1, w2)\n",
        "  a2 = np.tanh(z2)\n",
        "  #hiddenlayer3\n",
        "  z3 = np.dot(a2, w3)\n",
        "  a3 = np.tanh(z3)\n",
        "  #outputlayer\n",
        "  y_output = np.tanh(a3)\n",
        "  return a1, a2, a3, y_output"
      ],
      "metadata": {
        "id": "T6MrLlEyxxLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a1, a2, a3, y_output =  fwd_prop(X, w1, w2, w3)[0], fwd_prop(X, w1, w2, w3)[1], fwd_prop(X, w1, w2, w3)[2], fwd_prop(X, w1, w2, w3)[3]\n",
        "print(f\"a1 = {a1}\")\n",
        "print(f\"a2 = {a2}\")\n",
        "print(f\"a3 = {a3}\")\n",
        "print(f\"y_output = {y_output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOvp1W0bzDtT",
        "outputId": "db4c2283-f9b1-4eeb-afbd-37304f2fe7c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a1 = [ 0.76159416 -0.76159416]\n",
            "a2 = [-0.64201499  0.64201499]\n",
            "a3 = 0.8575549394724464\n",
            "y_output = 0.6949957700187085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error = y_target - y_output\n",
        "print(f\"error = {error}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DgQaK6t2pmx",
        "outputId": "89d9358e-1799-4db2-d518-3e0dc965ed8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error = 2.1650042299812915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4 Back Propagation\n",
        "For the backpropagation, the derivative of the activation function tanh was used with the output of the feed-forward propagation as the parameter. The output of the derivative was multiplied to the error in order to get the delta. With the delta already solved, the new third weight was solved by subtracting the initialized weight 3 minus the product of the delta, learning rate, and the output from its activation a3. Repeating the same steps on the other parameter will give the new second weight and the new first weight."
      ],
      "metadata": {
        "id": "_1MMqvnN1DcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bck_prop():\n",
        "  lr = 0.25\n",
        "  dr = (1-y_output)*(1+y_output)\n",
        "  delta = error * dr\n",
        "  wn1 = w3 - (lr*delta)*a3\n",
        "  dr1 = (1-a3)*(1+a3)\n",
        "  delta2 = np.dot(w2,dr1)*delta\n",
        "  wn2 = w2 - (lr*delta2)*a2\n",
        "  dr2 = (1-a2)*(1+a2)\n",
        "  delta3 = np.dot(w1, dr2)*delta2\n",
        "  wn3 = w1 - (lr*delta3)*a1\n",
        "\n",
        "  return wn1, wn2, wn3\n"
      ],
      "metadata": {
        "id": "HmrfPm521C3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5 New Weights\n",
        "After the process of forward and back propagation, #5 show the new weights of the given variable from #2. The program purpose is only to print the new values with the function of back propagation."
      ],
      "metadata": {
        "id": "2NV6b89V3loq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn1, wn2, wn3 = bck_prop()[0], bck_prop()[1], bck_prop()[2]\n",
        "print(f\"New Weight 3 = {wn1}\")\n",
        "print(f\"New Weight 2 = {wn2}\")\n",
        "print(f\"New Weight 1 = {wn3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3uoBAbm3Hno",
        "outputId": "dce41c43-0f6b-487f-c27c-2c2adb312d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Weight 3 = [-1.23995798  0.76004202]\n",
            "New Weight 2 = [[1.04753434 1.90493132]\n",
            " [2.09506868 0.95246566]]\n",
            "New Weight 1 = [[ 1. -1.]\n",
            " [-1.  1.]]\n"
          ]
        }
      ]
    }
  ]
}